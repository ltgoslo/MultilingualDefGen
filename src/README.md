```
├── modeling        # fine-tuning, prediction, mapping to shared task files, pushing to HF Hub
├── sense_label     # selecting a single definition for senses with many usage examples
├── token_stats     # statistics of how many tokens is produced for a sample by different tokenizers
analyse_circular.py # study circular definitions
*_formatting.py     # format input data
fmt*.py             # format output data
study_truncation.py # produce token_stats
```
